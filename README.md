# QA with PDF files using LLM, RAG and deploy in Chainlit
## Description:
- This project implements a Retrieval-Augmented Generation (RAG) model for large language models (LLMs). It leverages state-of-the-art deep learning techniques to enhance the performance and    capabilities of language models through retrieval-augmented generation. 

- The product of project is deploy in Chainlit, help user can QA with PDF files.

## Fetures:
- Upload file PDF to QA.
- Retrieval-Augmented Generation (RAG) for LLMs
- Integration with popular deep learning libraries
- Configurable parameters for customization
- Support for various data sources

## Installation:
To set up the environment for this project, follow these steps:
1. **Clone the repository**:
    ```sh 
    git clone https://github.com/undertanker86/QA-with-PDF-files-using-RAG-LLM.git
    cd rag-llm
2. **Create a conda environment using the environment.yml file**:
    ```sh 
    conda env create -f environment.yml
    conda activate config environment
## Run code:
    ```sh
    chainlit run rag-llm.py
## Result:
1. Upload file pdf and question:
![image](https://github.com/undertanker86/QA-with-PDF-files-using-RAG-LLM/assets/124110097/f1a143d6-bed3-4680-abaf-e1f895dfd02c)

2. The result:
   
![image](https://github.com/undertanker86/QA-with-PDF-files-using-RAG-LLM/assets/124110097/b729c9bc-9abf-48cb-af0a-0bf0cdfa01f8)

3. The information in PDF files:
![image](https://github.com/undertanker86/QA-with-PDF-files-using-RAG-LLM/assets/124110097/286f9b73-fa82-4ecd-83ee-093efe54f171)

    


